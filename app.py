import streamlit as st
import os
import tempfile
import asyncio
import uuid

try:
    import edge_tts
except ImportError:
    st.error("–ú–æ–¥—É–ª—å edge-tts –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω! –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∫–æ–º–∞–Ω–¥–æ–π: pip install edge-tts")
    st.stop()
try:
    from pydub import AudioSegment
    from pydub.utils import which
except ImportError:
    st.error("–ú–æ–¥—É–ª—å pydub –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω! –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∫–æ–º–∞–Ω–¥–æ–π: pip install pydub")
    st.stop()

# –ö–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ ffmpeg
if not which("ffmpeg"):
    st.warning("–í–Ω–∏–º–∞–Ω–∏–µ: ffmpeg –Ω–µ –Ω–∞–π–¥–µ–Ω! Pydub –Ω–µ —Å–º–æ–∂–µ—Ç –æ–±—ä–µ–¥–∏–Ω—è—Ç—å WAV. –°–∫–∞—á–∞–π—Ç–µ ffmpeg –∏ –¥–æ–±–∞–≤—å—Ç–µ –≤ PATH.")

EDGE_LIMIT = 3000
PREVIEW_LEN = 300
VOICE_DEFAULT = "en-US-JennyNeural"

MAX_EDGE_TTS_CHARS = 999999  # —Ä–∞–±–æ—á–∏–π –ª–∏–º–∏—Ç —Å –∑–∞–ø–∞—Å–æ–º

BEST_FEMALE = ['en-US-JennyNeural', 'en-US-AriaNeural', 'en-GB-LibbyNeural']
BEST_MALE = ['en-US-GuyNeural', 'en-GB-RyanNeural']

@st.cache_data(show_spinner=False)
def get_english_and_russian_voices():
    try:
        voices = asyncio.run(edge_tts.list_voices())
        en_voices = [v for v in voices if v.get('Locale', '').startswith('en-')]
        ru_voices = [v for v in voices if v.get('Locale', '').startswith('ru-')]
        best_female = [v for v in en_voices if v['ShortName'] in BEST_FEMALE]
        best_male = [v for v in en_voices if v['ShortName'] in BEST_MALE]
        rest_female = sorted([v for v in en_voices if v.get('Gender') == 'Female' and v not in best_female], key=lambda v: v.get('FriendlyName') or v['ShortName'])
        rest_male = sorted([v for v in en_voices if v.get('Gender') == 'Male' and v not in best_male], key=lambda v: v.get('FriendlyName') or v['ShortName'])
        ru_female = sorted([v for v in ru_voices if v.get('Gender') == 'Female'], key=lambda v: v.get('FriendlyName') or v['ShortName'])
        ru_male = sorted([v for v in ru_voices if v.get('Gender') == 'Male'], key=lambda v: v.get('FriendlyName') or v['ShortName'])
        return best_female, rest_female, best_male, rest_male, ru_female, ru_male
    except Exception as e:
        st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –≥–æ–ª–æ—Å–æ–≤ Edge TTS: {e}")
        return (
            [{'ShortName': 'en-US-JennyNeural', 'FriendlyName': 'en-US-JennyNeural', 'Gender': 'Female', 'Locale': 'en-US'}],
            [],
            [{'ShortName': 'en-US-GuyNeural', 'FriendlyName': 'en-US-GuyNeural', 'Gender': 'Male', 'Locale': 'en-US'}],
            [],
            [{'ShortName': 'ru-RU-SvetlanaNeural', 'FriendlyName': 'ru-RU-SvetlanaNeural', 'Gender': 'Female', 'Locale': 'ru-RU'}],
            [{'ShortName': 'ru-RU-DmitryNeural', 'FriendlyName': 'ru-RU-DmitryNeural', 'Gender': 'Male', 'Locale': 'ru-RU'}]
        )

def group_voices_with_dividers_and_russian(best_female, rest_female, best_male, rest_male, ru_female, ru_male):
    grouped = []
    # –ñ–µ–Ω—Å–∫–∏–µ
    if best_female or rest_female:
        grouped.append(('‚Äî‚Äî –ñ–µ–Ω—Å–∫–∏–µ ‚Äî‚Äî', None))
        grouped += [(v.get('FriendlyName', v['ShortName']), v['ShortName']) for v in best_female]
        grouped += [(v.get('FriendlyName', v['ShortName']), v['ShortName']) for v in rest_female]
    # –ú—É–∂—Å–∫–∏–µ
    if best_male or rest_male:
        grouped.append(('‚Äî‚Äî –ú—É–∂—Å–∫–∏–µ ‚Äî‚Äî', None))
        grouped += [(v.get('FriendlyName', v['ShortName']), v['ShortName']) for v in best_male]
        grouped += [(v.get('FriendlyName', v['ShortName']), v['ShortName']) for v in rest_male]
    # –†—É—Å—Å–∫–∏–µ
    if ru_female or ru_male:
        grouped.append(('‚Äî‚Äî –†—É—Å—Å–∫–∏–µ –≥–æ–ª–æ—Å–∞ ‚Äî‚Äî', None))
        if ru_female:
            grouped.append(('‚Äî –ñ–µ–Ω—Å–∫–∏–µ (RU) ‚Äî', None))
            grouped += [(v.get('FriendlyName', v['ShortName']), v['ShortName']) for v in ru_female]
        if ru_male:
            grouped.append(('‚Äî –ú—É–∂—Å–∫–∏–µ (RU) ‚Äî', None))
            grouped += [(v.get('FriendlyName', v['ShortName']), v['ShortName']) for v in ru_male]
    return grouped

def split_text(text, limit=EDGE_LIMIT):
    parts = []
    while len(text) > limit:
        split_idx = text.rfind('\n', 0, limit)
        if split_idx == -1 or split_idx < limit // 2:
            split_idx = limit
        parts.append(text[:split_idx])
        text = text[split_idx:]
    if text.strip():
        parts.append(text)
    return parts

def get_temp_mp3():
    return os.path.join(tempfile.gettempdir(), f"edge_tts_{uuid.uuid4().hex}.mp3")

def format_rate_volume(val):
    return f"{val:+d}%"

async def tts_to_mp3(text, voice, rate, volume, out_path):
    communicate = edge_tts.Communicate(
        text,
        voice,
        rate=format_rate_volume(rate),
        volume=format_rate_volume(volume)
    )
    await communicate.save(out_path)

# --- UI ---
st.set_page_config(page_title="–ù–µ–π—Ä–æ-–ì–æ–ª–æ—Å", layout="centered")
st.title("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∞–Ω–≥–ª–∏–π—Å–∫–æ–π –∏ —Ä—É—Å—Å–∫–æ–π –æ–∑–≤—É—á–∫–∏ —á–µ—Ä–µ–∑ Microsoft Edge TTS")

st.markdown("""
**–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è –æ–∑–≤—É—á–∫–∏:**
""")
text = st.text_area("–¢–µ–∫—Å—Ç –¥–ª—è –æ–∑–≤—É—á–∫–∏", height=200, key="input_text")

# –õ–∏–º–∏—Ç —Å–∏–º–≤–æ–ª–æ–≤
if len(text) > MAX_EDGE_TTS_CHARS:
    st.warning(f"–¢–µ–∫—Å—Ç –ø—Ä–µ–≤—ã—à–∞–µ—Ç –ª–∏–º–∏—Ç {MAX_EDGE_TTS_CHARS} —Å–∏–º–≤–æ–ª–æ–≤ –∏ –±—É–¥–µ—Ç –æ–±—Ä–µ–∑–∞–Ω!")
    text = text[:MAX_EDGE_TTS_CHARS]

best_female, rest_female, best_male, rest_male, ru_female, ru_male = get_english_and_russian_voices()
grouped_options = group_voices_with_dividers_and_russian(best_female, rest_female, best_male, rest_male, ru_female, ru_male)
labels = [opt[0] for opt in grouped_options]
shortnames = [opt[1] for opt in grouped_options]
real_indices = [i for i, s in enumerate(shortnames) if s is not None]

if 'selected_voice' not in st.session_state:
    st.session_state.selected_voice = VOICE_DEFAULT

col1, col2 = st.columns(2)
with col1:
    # –ò–Ω–¥–µ–∫—Å –ø–æ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω–æ–º—É –≥–æ–ª–æ—Å—É —Å—Ä–µ–¥–∏ –≤—Å–µ—Ö (—Å —É—á—ë—Ç–æ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–π)
    if st.session_state.selected_voice in shortnames:
        default_idx = shortnames.index(st.session_state.selected_voice)
    else:
        default_idx = real_indices[0] if real_indices else 0
    selected_idx = st.selectbox("–ì–æ–ª–æ—Å:", range(len(labels)), format_func=lambda i: labels[i], index=default_idx)
    # –ï—Å–ª–∏ –≤—ã–±—Ä–∞–Ω —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å ‚Äî –Ω–µ –º–µ–Ω—è–µ–º –≥–æ–ª–æ—Å
    if shortnames[selected_idx] is not None:
        st.session_state.selected_voice = shortnames[selected_idx]
    voice = st.session_state.selected_voice
with col2:
    # –û–ø–∏—Å–∞–Ω–∏–µ –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –≥–æ–ª–æ—Å–∞
    vinfo = next((v for v in best_female + rest_female + best_male + rest_male + ru_female + ru_male if v['ShortName'] == voice), None)
    if vinfo:
        st.markdown(f"**–í—ã–±—Ä–∞–Ω–Ω—ã–π –≥–æ–ª–æ—Å:** `{voice}`  ")
        st.markdown(f"*{vinfo.get('FriendlyName', voice)}*  ")
        st.markdown(f"**–†–µ–≥–∏–æ–Ω:** `{vinfo.get('Locale','')}`  |  **–ü–æ–ª:** `{vinfo.get('Gender','')}`")
    else:
        st.markdown(f"**–í—ã–±—Ä–∞–Ω–Ω—ã–π –≥–æ–ª–æ—Å:** `{voice}`")

rate = st.slider("–°–∫–æ—Ä–æ—Å—Ç—å (Rate, %)", -50, 50, 0, 1)
volume = st.slider("–ì—Ä–æ–º–∫–æ—Å—Ç—å (Volume, %)", -50, 50, 0, 1)

col3, col4 = st.columns(2)
preview_clicked = col3.button("üîä Preview (–ø–µ—Ä–≤—ã–µ 300 —Å–∏–º–≤–æ–ª–æ–≤)")
generate_clicked = col4.button("üéµ Generate WAV (–≤–µ—Å—å —Ç–µ–∫—Å—Ç)")

status = st.empty()

if preview_clicked and text.strip():
    preview_text = text[:PREVIEW_LEN]
    status.info("–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è –ø—Ä–µ–¥–ø—Ä–æ—Å–ª—É—à–∫–∞...")
    try:
        mp3_path = get_temp_mp3()
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        loop.run_until_complete(tts_to_mp3(preview_text, voice, rate, volume, mp3_path))
        audio = AudioSegment.from_file(mp3_path, format="mp3")
        wav_bytes = audio.export(format="wav").read()
        
        # –°–æ–∑–¥–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –ø—Ä–µ–¥–ø—Ä–æ—Å–ª—É—à–∫–∏
        col_preview_download, col_preview_play = st.columns(2)
        
        with col_preview_download:
            st.download_button("‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å –ø—Ä–µ–¥–ø—Ä–æ—Å–ª—É—à–∫—É", wav_bytes, file_name="preview.wav", mime="audio/wav")
        
        with col_preview_play:
            st.audio(wav_bytes, format="audio/wav", start_time=0)
        
        status.success("–ü—Ä–µ–¥–ø—Ä–æ—Å–ª—É—à–∫–∞ –≥–æ—Ç–æ–≤–∞!")
        os.remove(mp3_path)
    except Exception as e:
        status.error(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥–ø—Ä–æ—Å–ª—É—à–∫–∏: {e}")

if generate_clicked and text.strip():
    status.info("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–∑–≤—É—á–∫–∏...")
    parts = split_text(text)
    n_parts = len(parts)
    status.write(f"–¢–µ–∫—Å—Ç —Ä–∞–∑–±–∏—Ç –Ω–∞ {n_parts} —Å–µ–≥–º–µ–Ω—Ç(–æ–≤).")
    temp_mp3_files = []
    try:
        for i, part in enumerate(parts):
            status.write(f"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–µ–≥–º–µ–Ω—Ç–∞ {i+1}/{n_parts}...")
            mp3_path = get_temp_mp3()
            temp_mp3_files.append(mp3_path)
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            loop.run_until_complete(tts_to_mp3(part, voice, rate, volume, mp3_path))
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ mp3 –≤ –æ–¥–∏–Ω wav
        status.write("–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å–µ–≥–º–µ–Ω—Ç–æ–≤...")
        combined = AudioSegment.empty()
        for fname in temp_mp3_files:
            combined += AudioSegment.from_file(fname, format="mp3")
        out_path = os.path.join(os.getcwd(), "output.wav")
        combined.export(out_path, format="wav")
        for fname in temp_mp3_files:
            os.remove(fname)
        status.success(f"–ì–æ—Ç–æ–≤–æ! –ò—Ç–æ–≥–æ–≤—ã–π —Ñ–∞–π–ª: {out_path}")
        st.markdown(f"**–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É:** `{out_path}`")
        st.markdown(f"**–ì–æ–ª–æ—Å:** `{voice}`  |  **–°–µ–≥–º–µ–Ω—Ç–æ–≤:** {n_parts}")
        
        # –°–æ–∑–¥–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –∫–Ω–æ–ø–æ–∫ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –∏ –ø—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏—è
        col_download, col_play = st.columns(2)
        
        with col_download:
            with open(out_path, "rb") as f:
                st.download_button("‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å output.wav", f, file_name="output.wav", mime="audio/wav")
        
        with col_play:
            # –î–æ–±–∞–≤–ª—è–µ–º –∞—É–¥–∏–æ–ø–ª–µ–µ—Ä –¥–ª—è –ø—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏—è –≤ –±—Ä–∞—É–∑–µ—Ä–µ
            with open(out_path, "rb") as f:
                audio_bytes = f.read()
                st.audio(audio_bytes, format="audio/wav", start_time=0)
    except Exception as e:
        status.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
    finally:
        for fname in temp_mp3_files:
            if os.path.exists(fname):
                os.remove(fname)
st.markdown("---", unsafe_allow_html=True)

st.markdown("""
<div style="text-align: center; padding: 20px; background: #1e1e1e; border: 1px solid #333; border-radius: 12px; box-shadow: 0 4px 10px rgba(0,0,0,0.15); font-family: 'Segoe UI', sans-serif;">
    <div style="font-size: 24px; color: white; font-weight: bold; margin-bottom: 6px;">
         –ù–µ–π—Ä–æ-–ì–æ–ª–æ—Å
    </div>
    <div style="font-size: 15px; color: #999; margin-bottom: 12px;">
        –ù–µ–π—Ä–æ–Ω–æ–≤–æ 2025
    </div>
    <a href="https://github.com/neuronovo-X/neurovoice" target="_blank" style="color: #facc15; font-weight: bold; text-decoration: none; font-size: 16px;">
        üåü GitHub üåü 
    </a>
</div>
""", unsafe_allow_html=True)
